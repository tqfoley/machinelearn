{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdbb0286-37db-4b0a-aaa8-06729bf5adc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Begin minimal PyTorch Iris demo \n",
      "\n",
      "Training predictors:\n",
      "[[115.0, 1.5, 1.3, 0.2], [114.5, 1.3, 1.3, 0.3], [105.0, 1.5, 1.3, 0.2], [0.5, 2.6, 4.4, 1.2], [0.1, 2.0, 4.6, 1.4], [26.7, 3.1, 5.6, 4.4], [26.9, 4.1, 5.1, 2.3], [25.0, 5.5, 1.3, 4.3], [24.5, 2.3, 1.3, 4.3], [25.5, 6.6, 4.4, 1.2], [36.1, 7.0, 4.6, 1.4], [36.7, 8.1, 5.6, 2.4], [36.9, 3.1, 5.1, 2.3]]\n",
      "\n",
      "Training class labels: \n",
      "[0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]\n",
      "\n",
      "Starting training \n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "Done training \n",
      "\n",
      "Predicting species for   [[115.4, 1.8, 1.11, 0.4]]\n",
      "[[0.92  0.002 0.078]]\n",
      "\n",
      "End hardcoded predictMe\n",
      "process.csv\n",
      "['0.09', '6.62', '4.41', '1.4']\n",
      "\n",
      "Predicting species from file process.csv   [[0.09 6.62 4.41 1.4 ]]\n",
      "[[0.002 0.985 0.012]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "import torch as T\n",
    "device = T.device(\"cpu\")  # apply to Tensor or Module\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "class Net(T.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.hid1 = T.nn.Linear(4, 7)  # 4-7-3\n",
    "    self.oupt = T.nn.Linear(7, 3)\n",
    "    # (initialize weights)\n",
    "\n",
    "  def forward(self, x):\n",
    "    z = T.tanh(self.hid1(x))\n",
    "    z = self.oupt(z)  # no softmax. see CrossEntropyLoss() \n",
    "    return z\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# 0. get started\n",
    "print(\"\\nBegin minimal PyTorch Iris demo \")\n",
    "T.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "  \n",
    "# 1. set up training data\n",
    "#print(\"\\nLoading Iris train data \")\n",
    "#train_x3 = np.array([\n",
    "#  [5.0, 1.5, 1.3, 0.2],     0\n",
    "#  [4.5, 1.3, 1.3, 0.3],     0\n",
    "#  [0.5, 2.6, 4.4, 1.2],     1\n",
    "#  [0.1, 2.0, 4.6, 1.4],     1\n",
    "#  [26.7, 3.1, 5.6, 4.4],    2\n",
    "#  [26.9, 4.1, 5.1, 2.3],    2\n",
    "#  [25.0, 5.5, 1.3, 4.3],    2\n",
    "#  [24.5, 2.3, 1.3, 4.3],    2\n",
    "#  [25.5, 6.6, 4.4, 1.2],    2\n",
    "#  [36.1, 7.0, 4.6, 1.4],    2\n",
    "#  [36.7, 8.1, 5.6, 2.4],    2\n",
    "#  [36.9, 3.1, 5.1, 2.3]], dtype=np.float32)\n",
    "\n",
    "#print(train_x2)\n",
    "\n",
    "#datafile = open('irisTrain.csv', 'r')\n",
    "#datareader = csv.reader(datafile, delimiter=';')\n",
    "#data = []\n",
    "#for row in datareader:\n",
    "#    row = [float(x) for x in row]\n",
    "#    data.append(row)\n",
    "\n",
    "train_x = []\n",
    "with open('irisTrain.csv', 'r') as datafile:\n",
    "    datareader = csv.reader(datafile, delimiter=',')\n",
    "    data = []\n",
    "    for row in datareader:\n",
    "        #print(row)\n",
    "        row = [float(x) for x in row]\n",
    "        data.append(row)\n",
    "        \n",
    "#print(\"\\nData from irisTrain.csv\")\n",
    "#print (data)\n",
    "train_x = data\n",
    "\n",
    "#train_y = np.array([0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2], dtype=np.float32)\n",
    "train_y = []\n",
    "with open('irisTarget.csv', 'r') as datafile:\n",
    "    datareader = csv.reader(datafile, delimiter=',')\n",
    "    for row in datareader:\n",
    "        #print(row)\n",
    "        row = [float(x) for x in row]\n",
    "        train_y = (row)\n",
    "\n",
    "print(\"\\nTraining predictors:\")\n",
    "print(train_x)\n",
    "print(\"\\nTraining class labels: \")\n",
    "print(train_y)\n",
    "\n",
    "train_x = T.tensor(train_x, dtype=T.float32).to(device)\n",
    "train_y = T.tensor(train_y, dtype=T.long).to(device)\n",
    "\n",
    "# 2. create network\n",
    "net = Net().to(device)    # could use Sequential()\n",
    "\n",
    "# 3. train model\n",
    "max_epochs = 100\n",
    "lrn_rate = 0.04\n",
    "loss_func = T.nn.CrossEntropyLoss()  # applies softmax()\n",
    "optimizer = T.optim.SGD(net.parameters(), lr=lrn_rate)\n",
    "\n",
    "print(\"\\nStarting training \")\n",
    "net.train()\n",
    "indices = np.arange(6)\n",
    "for epoch in range(0, max_epochs):\n",
    "  print(epoch)\n",
    "  np.random.shuffle(indices)\n",
    "  for i in indices:\n",
    "    X = train_x[i].reshape(1,4)  # device inherited\n",
    "    Y = train_y[i].reshape(1,)\n",
    "    optimizer.zero_grad()\n",
    "    oupt = net(X)\n",
    "    loss_obj = loss_func(oupt, Y)\n",
    "    loss_obj.backward()\n",
    "    optimizer.step()\n",
    "  # (monitor error)\n",
    "print(\"Done training \")\n",
    "\n",
    "\n",
    "\n",
    "predictMe = [[115.4, 1.8, 1.11, 0.4]]\n",
    "# 5. use model to make a prediction\n",
    "net.eval()\n",
    "print(\"\\nPredicting species for  \", predictMe)\n",
    "unk = np.array(predictMe, dtype=np.float32)\n",
    "unk = T.tensor(unk, dtype=T.float32).to(device) \n",
    "logits = net(unk).to(device)\n",
    "probs = T.softmax(logits, dim=1)\n",
    "probs = probs.detach().numpy()  # allows printoptions\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "print(probs)\n",
    "\n",
    "print(\"\\nEnd hardcoded predictMe\")\n",
    "\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# List all files and folders in the current directory\n",
    "files = os.listdir(current_directory)\n",
    "\n",
    "#print(files) # Returns ['my_data, 'airbnb_data.csv']\n",
    "\n",
    "for file in files:\n",
    "  if (file.find(\"process\")==0):\n",
    "    print(file)\n",
    "\n",
    "    with open(file, 'r') as f:\n",
    "      reader = csv.reader(f)\n",
    "      predictdata = list(reader)\n",
    "      print(predictdata[0])\n",
    "      predictdata = np.array(predictdata, dtype=float)\n",
    "      print(\"\\nPredicting species from file process.csv  \", predictdata)\n",
    "      unk = np.array(predictdata, dtype=np.float32)\n",
    "      unk = T.tensor(unk, dtype=T.float32).to(device) \n",
    "      logits = net(unk).to(device)\n",
    "      probs = T.softmax(logits, dim=1)\n",
    "      probs = probs.detach().numpy()  # allows printoptions\n",
    "\n",
    "      np.set_printoptions(precision=3)\n",
    "      print(probs)\n",
    "      time.sleep(2) # Sleep\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fb28d4-dd7b-4e1c-88a8-e78966ae62b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3f5a71-21b8-41b5-80ca-f286bad0f9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
